ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
Selected Tasks: ['folio-scratchpad-2shot']
Loading the model and tokenizer from HF (in fp32)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.37s/it]
number of problems for this task is 3
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:31<01:03, 31.59s/it] 67%|██████▋   | 2/3 [01:21<00:42, 42.32s/it]100%|██████████| 3/3 [02:06<00:00, 43.71s/it]100%|██████████| 3/3 [02:06<00:00, 42.26s/it]
/app/linc/eval/evaluator.py:46: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions
  warnings.warn(
raw generations were saved
processed generations were saved
references were saved
{
  "config": {
    "model": "mistralai/Mistral-7B-v0.1"
  },
  "folio-scratchpad-2shot": {
    "accuracy (pass@1 majority)": 1.0
  }
}
