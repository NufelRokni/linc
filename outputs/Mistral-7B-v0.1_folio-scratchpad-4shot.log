ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
Selected Tasks: ['folio-scratchpad-4shot']
Loading the model and tokenizer from HF (in fp32)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.39s/it]
number of problems for this task is 3
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:48<01:37, 48.92s/it] 67%|██████▋   | 2/3 [02:10<01:07, 67.90s/it]100%|██████████| 3/3 [03:05<00:00, 62.40s/it]100%|██████████| 3/3 [03:05<00:00, 61.98s/it]
/app/linc/eval/evaluator.py:46: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions
  warnings.warn(
raw generations were saved
processed generations were saved
references were saved
{
  "config": {
    "model": "mistralai/Mistral-7B-v0.1"
  },
  "folio-scratchpad-4shot": {
    "accuracy (pass@1 majority)": 0.3333333333333333
  }
}
