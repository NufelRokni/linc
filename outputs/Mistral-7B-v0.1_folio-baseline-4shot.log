ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
Selected Tasks: ['folio-baseline-4shot']
Loading the model and tokenizer from HF (in fp32)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.35s/it]
number of problems for this task is 3
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:05<00:10,  5.09s/it] 67%|██████▋   | 2/3 [00:10<00:05,  5.15s/it]100%|██████████| 3/3 [00:15<00:00,  5.15s/it]100%|██████████| 3/3 [00:15<00:00,  5.15s/it]
/app/linc/eval/evaluator.py:46: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions
  warnings.warn(
raw generations were saved
processed generations were saved
references were saved
{
  "config": {
    "model": "mistralai/Mistral-7B-v0.1"
  },
  "folio-baseline-4shot": {
    "accuracy (pass@1 majority)": 0.0
  }
}
